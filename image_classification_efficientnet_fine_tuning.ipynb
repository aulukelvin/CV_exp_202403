{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gj0lhbFKIvuL"
      },
      "source": [
        "## Setup and data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocEPn-arIvuL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf  # For tf.data\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.applications import EfficientNetB0, EfficientNetV2S, InceptionV3\n",
        "\n",
        "# IMG_SIZE is determined by EfficientNet model choice\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 64\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhLFCejsIvuM"
      },
      "outputs": [],
      "source": [
        "dataset_name = \"stanford_dogs\"\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    dataset_name, split=[\"train\", \"test\"], with_info=True, as_supervised=True\n",
        ")\n",
        "NUM_CLASSES = ds_info.features[\"label\"].num_classes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcbsZWFCIvuN"
      },
      "source": [
        "When the dataset include images with various size, we need to resize them into a\n",
        "shared size. The Stanford Dogs dataset includes only images at least 200x200\n",
        "pixels in size. Here we resize the images to the input size needed for EfficientNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_8VmtvnIvuN"
      },
      "outputs": [],
      "source": [
        "size = (IMG_SIZE, IMG_SIZE)\n",
        "ds_train = ds_train.map(lambda image, label: (tf.image.resize(image, size), label))\n",
        "ds_test = ds_test.map(lambda image, label: (tf.image.resize(image, size), label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHKvWzzmIvuO"
      },
      "source": [
        "### Visualizing the data\n",
        "\n",
        "The following code shows the first 9 images with their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efFN9H08IvuO"
      },
      "outputs": [],
      "source": [
        "\n",
        "def format_label(label):\n",
        "    string_label = label_info.int2str(label)\n",
        "    return string_label.split(\"-\")[1]\n",
        "\n",
        "\n",
        "label_info = ds_info.features[\"label\"]\n",
        "for i, (image, label) in enumerate(ds_train.take(9)):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "    plt.title(\"{}\".format(format_label(label)))\n",
        "    plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMhS8UF-IvuO"
      },
      "source": [
        "### Data augmentation\n",
        "\n",
        "We can use the preprocessing layers APIs for image augmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_3m6FXzIvuP"
      },
      "outputs": [],
      "source": [
        "img_augmentation_layers = [\n",
        "    layers.RandomRotation(factor=0.15),\n",
        "    layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n",
        "    layers.RandomFlip(),\n",
        "    layers.RandomContrast(factor=0.1),\n",
        "]\n",
        "\n",
        "\n",
        "def img_augmentation(images):\n",
        "    for layer in img_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Pk5WP_sIvuP"
      },
      "source": [
        "This `Sequential` model object can be used both as a part of\n",
        "the model we later build, and as a function to preprocess\n",
        "data before feeding into the model. Using them as function makes\n",
        "it easy to visualize the augmented images. Here we plot 9 examples\n",
        "of augmentation result of a given figure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DGQSU_rBIvuP"
      },
      "outputs": [],
      "source": [
        "for image, label in ds_train.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        aug_img = img_augmentation(np.expand_dims(image.numpy(), axis=0))\n",
        "        aug_img = np.array(aug_img)\n",
        "        plt.imshow(aug_img[0].astype(\"uint8\"))\n",
        "        plt.title(\"{}\".format(format_label(label)))\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkgU3jXvIvuP"
      },
      "source": [
        "### Prepare inputs\n",
        "\n",
        "Once we verify the input data and augmentation are working correctly,\n",
        "we prepare dataset for training. The input data are resized to uniform\n",
        "`IMG_SIZE`. The labels are put into one-hot\n",
        "(a.k.a. categorical) encoding. The dataset is batched.\n",
        "\n",
        "Note: `prefetch` and `AUTOTUNE` may in some situation improve\n",
        "performance, but depends on environment and the specific dataset used.\n",
        "See this [guide](https://www.tensorflow.org/guide/data_performance)\n",
        "for more information on data pipeline performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjyC2nsCIvuP"
      },
      "outputs": [],
      "source": [
        "\n",
        "# One-hot / categorical encoding\n",
        "def input_preprocess_train(image, label):\n",
        "    image = img_augmentation(image)\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "def input_preprocess_test(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "\n",
        "ds_train = ds_train.map(input_preprocess_train, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_train = ds_train.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n",
        "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(input_preprocess_test, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "ds_test = ds_test.batch(batch_size=BATCH_SIZE, drop_remainder=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxLBbDFeIvuP"
      },
      "source": [
        "## Training a model from scratch\n",
        "\n",
        "We build an EfficientNetB0 with 120 output classes, that is initialized from scratch:\n",
        "\n",
        "Note: the accuracy will increase very slowly and may overfit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm_roUgsIvuQ"
      },
      "outputs": [],
      "source": [
        "model = EfficientNetB0(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    classes=NUM_CLASSES,\n",
        "    input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        ")\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "epochs = 40  # @param {type: \"slider\", min:10, max:100}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6y48v9OIvuQ"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_hist(hist):\n",
        "    plt.plot(hist.history[\"accuracy\"])\n",
        "    plt.plot(hist.history[\"val_accuracy\"])\n",
        "    plt.title(\"model accuracy\")\n",
        "    plt.ylabel(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LO9-Q4TIvuQ"
      },
      "source": [
        "## Transfer learning from pre-trained weights\n",
        "\n",
        "Here we initialize the model with pre-trained ImageNet weights,\n",
        "and we fine-tune it on our own dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH8qrpgHIvuQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    model = EfficientNetB0(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ0U31OrIvuR"
      },
      "outputs": [],
      "source": [
        "model = build_model(num_classes=NUM_CLASSES)\n",
        "\n",
        "epochs = 25  # @param {type: \"slider\", min:8, max:80}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "plot_hist(hist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dft1V8keIvuR"
      },
      "outputs": [],
      "source": [
        "\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=1e-5)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n",
        "\n",
        "epochs = 4  # @param {type: \"slider\", min:4, max:10}\n",
        "hist = model.fit(ds_train, epochs=epochs, validation_data=ds_test)\n",
        "plot_hist(hist)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification_efficientnet_fine_tuning",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}